version: '3.7'

services:

  elasticsearch:
    image: docker.elastic.co/elasticsearch/elasticsearch:6.6.2
    networks:
      - elasticsearch
    environment:
      discovery.type: single-node
    volumes:
      - /data/elasticsearch/conf:/usr/share/elasticsearch/config
      - /data/elasticsearch/data:/usr/share/elasticsearch/data
      - /data/elasticsearch/logs:/usr/share/elasticsearch/logs
      - type: tmpfs
        target: /tmp
        tmpfs:
          size: 104857600 # 100 Mb
    deploy:
      placement:
        constraints:
          - node.hostname == swarm01

  kibana:
    image: docker.elastic.co/kibana/kibana:6.6.2
    networks:
      - nginx
      - elasticsearch
    environment:
      SERVER_NAME: kibana.services.ruware.com
      ELASTICSEARCH_URL: "http://elasticsearch:9200"
      NODE_OPTIONS: --max-old-space-size=200

  logstash:
    image: docker.elastic.co/logstash/logstash:6.6.2
    networks:
      - elasticsearch
      - logstash
    ports:
      - mode: host
        target: 8097
        published: 8097
        protocol: tcp
      - mode: host
        target: 12201
        published: 12201
        protocol: udp
    # Note that environment variables change logstash.yml file inplace, so it is better to choose one config method
    environment:
      HTTP_HOST: "0.0.0.0"
      XPACK_MONITORING_ELASTICSEARCH_URL: "http://elasticsearch:9200"
      CONFIG_RELOAD_AUTOMATIC: "true"
      CONFIG_RELOAD_INTERVAL: "5s"
    volumes:
      - /data/configs/logstash/logstash.conf:/usr/share/logstash/pipeline/logstash.conf:ro
      - /data/logstash:/usr/share/logstash/data
    deploy:
      placement:
        constraints:
          - node.hostname == swarm01

networks:
  nginx:
    external: true
    name: httpd_nginx
  elasticsearch:
  logstash:
